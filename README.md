# CHI 2021 - RCEA-360VR source code

Source code for CHI 2021 paper:
>*RCEA-360VR: Real-time, Continuous Emotion Annotation in 360° VR Videos for Collecting Precise Viewport-dependent Ground Truth Labels*

Repository contains:

1. [Viewport-dependent annotation fusion method](source)
2. [Viewport-based fine-grained V-A video overlay generator + example videos](video_results)

*[Explanation of source code will be finalized soon!]*

---

Preprint (.pdf): [https://abdoelali.com/pdfs/chi2021_rcea360vr_preprint.pdf](https://abdoelali.com/pdfs/chi2021_rcea360vr_preprint.pdf)

30s video preview:

[![30s video preview](https://abdoelali.com/assets/rcea360vr_thumbnail.png)](https://www.youtube.com/watch?v=dSeCyH6OuIc "CHI 2021 RCEA-360VR")

---

**Please cite our paper in any published work that uses any of these resources.**

BiBTeX:
```
@inproceedings{Xue2021,
  title = {RCEA-360VR: Real-time, Continuous Emotion Annotation in 360° VR Videos for Collecting Precise Viewport-dependent Ground Truth Labels},
  author = {Tong Xue and Abdallah El Ali and Tianyi Zhang and Gangyi Ding and Pablo Cesar},
  booktitle = {Proceedings of the International Conference on Human Factors in Computing Systems 2021},
  series = {CHI '21},
  year = {2021},
  location = {Yokohama, Japan},
  pages = {1-15},
  url = {https://doi.org/10.1145/3411764.3445487}
  }
  ```

ACM Ref Citation:

*Tong Xue, Abdallah El Ali, Tianyi Zhang, Gangyi Ding, and Pablo Cesar (2021). RCEA-360VR: Real-time, Continuous Emotion Annotation in 360° VR Videos for Collecting Precise Viewport-dependent Ground Truth Labels. In CHI Conference on Human Factors in Computing Systems (CHI ’21), May 8–13, 2021, Yokohama, Japan. ACM, New York, NY, USA, 15 pages. https://doi.org/10.1145/3411764.3445487*
